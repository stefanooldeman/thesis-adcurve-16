\chapter{Resultaten}

In dit hoodstuk worden alle resultaten uit het onderzoek gepresenteerd
Deelvraag 1 "Wat zijn de functionele en niet functionele eisen, waaraan de oplossing moet voldoen?" wordt beantwoord in \ref{sec:deelvraag1} \\

Deelvraag 2 "Wat zijn toonaangevende methodes en technologieën om statistieken te berekenen, en passen bij de wensen en eisen van de opdracht?"\  wordt beantwoord in \ref{sec:deelvraag2} \\

In \ref{sec:deelvraag3} wordt gekeken naar "Welke scenario's komen met regelmaat voor waardoor gegevens niet te verklaren zijn"\  
De resultaten van deelvraag 3a zijn te lezen in \ref{subsec:deelvraag3a} en deelvraag 3b in \ref{subsec:deelvraag3b} \\

In Deelvraag 4 is beantwoord in \ref{sec:deelvraag4} wordt belicht hoe de expirementen zijn ontworpen \\

Conclusies en een vergelijking wordt gemaakt in het betantwoorden van Deelvraag 5 "Wat zijn de gepresenteerde oplossingen en waarom zijn deze volledig of niet?" te lezen in \ref{sec:deelvraag5}

% MAIN QUESTION: "Hoe verzorgt een nieuwe implementatie voor het up-to-date houden van statistieken in Adcurve zodat gegevens altijd te verklaren zijn?"

\clearpage

% ACTIVITY Afleggen interviews rondom Requirements \& Constraints, documenteren use-cases
% RESULT MosCow prioriteiten lijst en checklist
\section{Functionele en niet functionele eisen}
\label{sec:deelvraag1}

Wat zijn de functionele en niet functionele eisen, waaraan de oplossing moet voldoen?

In een interview zijn de functionele en niet functionele eisen gegeven door Matthijs Jorissoen. De studen heeft 

[TODO: geef extra uitleg over de gebruikte methode MoSCoW]

\begin{comment}
Een functionele eis kan gezien worden als iets dat de gebruiker nodig heeft om het doel te bereiken of een bepaalde voorwaarde waaraan de oplossing moet voldoen.

Een non functionele eis is een beperking doe wordt opgelegd op een mogelijke oplossing, met het doel om functionele eisen te behalen of het doel van het project.
\end{comment}

\begin{table}[bh]
\centering
\caption{lijst van eisen geprioritiseerd met behulp van de MoSCoW analyse}
\label{table:requirements}
\def\arraystretch{1.5}
\begin{tabular}{|l|p{13cm}|}
\hline
\textbf{Prioriteit} & \textbf{Functionaliteit/Requirement}
\\ \hline
Must have           & Statistieken voor één webwinkel kunnen opnieuw worden gegenereerd zodat veranderingen in externe data bronnen bijvoorbeeld orders of geïmporteerde kosten opnieuw worden geaggregeerd. Dit moet tot 30 dagen terug.
\\ \hline
Must have           & Het creëren van data aggregatie voor alle webwinkels over een dag, mag niet meer tijd in beslag nemen dan de huidige oplossing nodig heeft. Dit is 1 uur en 30 minuten.
\\ \hline
Must have           & De kosten voor eventuele licenties en infrastructuur mogen niet hoger zijn dan dat voor de huidige oplossing vereist is
\\ \hline
Should have         & Statistieken zijn altijd voor kantoor uren beschikbaar voor het dashboard en latere processen zoals tips generatie
\\ \hline
Should have         & De gekozen oplossing heeft een productief programmeermodel en uitvoerbaar op niet afhankelijk van een hardware architectuur
\\ \hline
Could have         & De programmatuur is testbaar en hierdoor eenvoudig te onderhouden
\\ \hline
Could have          & Data aggregaties voor een groep webwinkels kunnen op een ander tijdstip worden geaggregeerd i.v.m. verschillende tijdszones
\\ \hline
Could have         & De nieuwe oplossing moet schaalbaar genoeg zijn om 10.000 klanten te kunnen onderstuenen.
\\ \hline
\end{tabular}
\end{table}

Een aantal gebruikte termen zoals simpel, snel etc. worden verduidelijkt met de bijbehorende definities die in overleg tot stand zijn gekomen: \\

\begin{itemize}
    \item \textbf{Een productief programmeermodel} in de context van een dit project wordt omschreven in \cite{asanovic2006landscape}: "programming models should be independent of the number of processors, they should allow programmers to use a richer set of data types and sizes, and they should support successful and well-known parallel models of parallelism"

    \item \textbf{Scalability} wordt door \cite{dubey2005recognition} gefefineerd als: Schaalbaarheid is het vermogen om de gewenste snelheid te bieden en te onderhouden al dan niet verbeteren. De industrie hier twee manieren voor. "Scale up" is de methode waarbij hardware wordt vervangen zodat er betere prestatie geleverd kan worden. Bij "scale out" wordt er extra hardware aangesloten zodat een bestaand systeem de toenemende werkdruk kan ondersteunen.
\end{itemize}

\begin{comment}
De grootte van alle databronnen voor een webwinkel per dag ligt tussen de 0.5 MB en 130 MB per dag. Om de data grootte in te schatten met 10.000 webwinkels kan huidige datagrootte van een gemiddelde dag worden ge-extrapoleert. Er moet rekeningen worden gehouden met het Paretoprincipe, dat zou verklaren dat 20\% van de webwinkels verantwoordelijk is voor 80\% van de datagrootte. Dit is ook waar te namen in het analyseren van de datasets. % https://en.wikipedia.org/wiki/Pareto_principle

\end{comment}


\clearpage

% ACTIVITY Onderzoeken van toonaangevende, passende technologieën
\section{Toonaangevende methodes en technologieën}
\label{sec:deelvraag2}

Wat zijn toonaangevende methodes en technologieën om statistieken te berekenen, en passen bij de wensen en eisen van de opdracht?

Uit verschillende bronnen zijn richtingen gevonden voor mogelijke oplossingen. Zoals het gebruik van databases[1],[2],[3] parallel programming[1],[4],[5], en hardware performance.

% https://www.experfy.com/blog/hadoop-market-size-adoption-growth-2020/
% [1]: https://github.com/onurakpolat/awesome-bigdata#columnar-databases
% [4]: http://www.cs.arizona.edu/~bkmoon/papers/sigmodrec11.pdf
% [5]: http://www.datanami.com/2014/11/21/spark-just-passed-hadoop-popularity-web-heres/
% [6]: http://radar.oreilly.com/2014/01/a-compelling-family-of-dsls-for-data-science.html

\subsection{Databaseses}

De volgende lijst van database systemen beschikken over analytical functionaliteiten nodig voor het aggregeren en creeëren van statestieken. Voor het maken van data aggregaties zijn baisis SQL functies nodig: SUM, MIN, MAX, AVERAGE, samen met de SQL clauses: GROUP BY en HAVING. Omdat bijna alle database systemen deze functies onderstuenen is er gekeken naar databases die een hoog volume aan data kunnen verwerken. 
Omdat er nu per dag zo'n 1.8Gb aan data voor alleen visits wordt verwerkt en dit extropaleert naar (1.8/480) * 100000 = 375Gb per dag. \\

Hierdoor kunnen veel traditionele databases niet worden beschouwd als een verkiesbare technologie. Daarom is gekeken naar databases met een andere storage engine. \\

Opvallend is dat veel databases die vandaag door grootte Bigdata bedrijven\footnote{} worden aangeboden 
% https://wiki.postgresql.org/wiki/PostgreSQL_derived_databases
Hieruit valt te concluderen dat de business intelligence industry veel research heeft geinvesteerd in op basis van Postgress technology. \\

Michael Stonebraker is origineel auteur Postgress en later vele high performance databases. In zijn paper "How To Build a High-Performance Data Warehouse" omschrijft hij drie verschillende architectuur typen / storage engines: Shared Memory, Shared Disk en Shared Nothing.
"Because shared nothing does not typically have nearly as severe bus or resource contention as shared-memory or shared-disk machines, shared nothing can be made to scale to hundreds or even thousands
of machines. Because of this, it is generally regarded as the best-scaling architecture". \parencite{dewitt2006build}



In de paper worden de volgende databases genoemd:
\begin{table}[bh]
\centering
\caption{My caption}
\label{my-label}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Shared memory} & \textbf{Shared Disk} & \textbf{Shared Nothing} \\ \hline
Microsoft SQL Server   & Oracle RAC           & Teradata \\
\hline
PostgresSQL            & Sysbase IQ           & Netezza \\
\hline
MySQL                  &                      & IBM DB2 \\
\hline
                       &                      & GreenplumDB \\
\hline
                       &                      & Vertica \\
\hline
\end{tabular}
\end{table}

\clearpage

\subsection{Parallel programming}

In 2009 werd geconstateerd door \cite{aarnio2009parallel} werd MapReduce als geidentificeerd als een "Prominent parallel data processing tool" dat tractie kreeg vanuit zowel de industrie als de academische wereld. Zo concludeerde zij dat: "Naast traditionele Database Management Systems is Map Reduce een zeer schaalbaar en flexibele oplossing is voor een variatie aan data analyses" \parencite{aarnio2009parallel} \\

Voor langere tijd nu, staat Hadoop bekende als een volwasse technologie en implementatie van Map Reduce, zo schrijft Gartner in een recent rapport: "The open-source software framework known as Apache Hadoop has gained sizable acceptance in organizations, spurred on by the growing digital business appetite for big data" \parencite{hadoop2013selection}. \\


"Joe Hellerstein, our local expert in databases, said the future of databases was large data
collections typically found on the Internet. A key primitive to explore such collections is
MapReduce, developed and widely used at Google \parencite{dean2008mapreduce}" \parencite{asanovic2006landscape}, 

Kort nadat UC Berkley zijn cluster framework "Spark" heeft gedoneerd aan de Apache foundation in 2014, heeft het project enorme aandacht ontvangen vanuit de hele industrie. \parencite{spark2015intro}. Zo is er ook vanuit Shop2market enorme interesse in Apache Spark. Er zijn al eerder in 2015 Proof of Concept uitgevoerd met betrekking tot machine learning applicaties. \\

Terwijl nog veel organisaties zweven tussen het begrijpen en het vinden van de toepassing voor Hadoop \parencite{hadoop2015adoption}, is sinds 2013 een alternatief in memory implementatie van o.a. Map reduce enorm populair  \parencite{spark2015intro}

\subsubsection{Conclusie}

De uiteindelijke selectie voor dit onderzoek is beperkt. De frameworks die zijn geselecteerd hebben genoeg herkenning vanuit de organisatie en industrie. De enorme lijst op github is getuige van de enorme hype rondom Big Data. Toch zijn veel organisaties nog zoekend naar wat technologie betekent en hoe het waarde toevoegd\parencite{hadoop2015adoption}.

Verder zijn er in de eerder genoemde lijst (github) enorm veel tools benoemd. In dit onderzoek zullen naast Hadoop en Naast eerder besproken frameworks Spark en Hadoop zijn er andere technologieën waar colleg's eerdere ervaring mee hebben.

De selectie van technologieën komt uit op

\begin{itemize}
    \item Disco
    \item Apache Flink
    \item Hadoop (Apache MapReduce)
    \item Apache Spark
\end{itemize}

Streaming methodes zoals bijvoorbeerld Apache Storm zijn worden als toonaangeevend gezien maar zijn niet geselecteerd. Dit omdat de vorm waarin de data beschikbaar wordt gesteld aan het aggregatie proces altijd in batch is. Het valt buiten de scope om deze data flows te veranderen.

\clearpage

\subsection{Hardware solutions}

High performance Domain Specific Languages zijn veelbelovend.

http://reconfigurablecomputing4themasses.net/files/1.2%20Kunle.pdf

Verilog (VHDL)
CUDA
OpenCL
Threads in (Java C++)
OpenMP

Zijn embedded programmeer talen die wel maximaal gebruik kunnen maken van hardware capiciteit. Echter is het programmer model niet vriendelijk en niet compatible met ieder platform.



Het programmeren van hardware is mogelijk met talen zoals CUDA, OpenCL en OpenMP. Deze worden in de rest van deze thesis benoemd als hardware frameworks. Echter zijn dit geen geschikte kandidaten omdat geen geschikt programmeer model bieden. Zo wordt wordt herkend door de Machine learning researchers van (Standfort University) \cite{sujeeth2011optiml} dat deze talen niet productief genoeg zijn om effectief problemen op te lossen en maximaal gebruik te maken van de hardware componenten zoals CPU en GPU. Dit komt omdat de programmeur direct te maken krijgt met complexiteit van het paralliseren van functies en moet tevens rekening houden met hardware specifieken uitdagingen. \parencite{chafi2010language} \\

Terwijl \cite{sujeeth2011optiml} OptiML presenteerd als een alternatief is het project\footnote{Zie de website van OptiML: https://stanford-ppl.github.io/Delite/optiml/index.html} nog altijd in Alpha versie. Echter is in 2014 door hetzelfde team Forge gepresenteerd. Een DSL voor hardware frameworks waar de test resultaten erg veelbelovend zijn. "Forge-generated Delite DSLs perform within 2x of hand-optimized C++ and up to 40x better than Spark, an alternative high-level distributed programming environment." \parencite{sujeeth2014forge}


Naast de gevonden technologieën wordt binnen shop2market veel gebruik gemaakt van Golang. (verdere uitleg nodig)
Vanuit de organisatie zijn hier in 2014 Proof Of Concepts mee gedaan waarin het concurrency model en performance is vergelijken met andere Akka (scala), Erlang en Java. Hierin waren Java en Golang even snel, echter is Golang een moderne programmeer taal waarin het concurrency model anders is geimplementeerd. Hierdoor hoeft geen rekening te houden met Threads.

Rust

\subsubsection{Conclusie}

De selectie van technologieën komt uit op

\begin{itemize}
    \item Forge
    \item Golang
\end{itemize}


\subsection{Conclusies}

Er zijn een aantal oplossings richtingen gevonden:
- clustered databases analytics / datawarehouses (RDBMS): google bigquery, vertica, redshift, hadoopDb, Teradata
- map reduce platform: spark, hadoop, disco etc.
- Hardware, software solutions: Forge en Golang Python, MATLAB, R, Golang, Rust


\clearpage

% ACTIVITY Impact analyse uitvoeren rondom use-cases
\section{Problematische scenario 's}
\label{sec:deelvraag3}

\textit{Welke scenario's komen met regelmaat voor waardoor gegevens niet te verklaren zijn?}

% Hiervoor zijn anekdotes verzameld van stakeholders waarbij zei vertelden over scenario 's die voor verwarring zorgen bij gebruikers.

Uit interview met verschillende stakeholders binnen shop2market zijn een aantal problematische scenario's besproken. Deze hebben geleidt tot de functionele en non functionele eisen in tabel \ref{table:requirements}. Veel van de gegeven verklaringen zijn symptomen van het probleem.


\begin{enumerate}
    \item De kosten van publishers worden geïmporteerd, wanneer het voorkomt dat niet alle kosten worden gematcht op bijbehorende producten; worden niet alle kosten verwerkt. Hierdoor komen de totalen niet overeen met externe dashboards, zoals die van de publisher (Adwords, Admarkt etc). \\
    
    \item Bij het bekijken van dashboards in Adcurve zijn de gegevens over de vorige dag pas beschikbaar na 12:30 CET. Omdat alle data in een keer wordt geaggregeerd kan het proces worden gestart nadat alle afhankelijke data bronnen beschikbaar zijn. Door een publisher wordt de data beschikbaar gemaakt na 10 uur s\'ochtends. Daarom start het proces pas om 11 uur. \\
    
    \item Door middel van \textit{tracking} worden er orders van de webwinkels gesynchroniseerd. Wanneer hier foutieve bedragen tussen zitten beïnvloed de totale winstgevendheid. Hierdoor kan er veel onduidelijkheid ontstaan. \\
\end{enumerate}

Daarom wordt in de volgende deelvraag \ref{subsec:deelvraag3a} onderzocht wat de achterliggende oorzaak is per scenario.

\clearpage

% ACTIVITY Onderzoek technische factoren die voor problemen zorgen
\subsection{Wat zijn de technische factoren?}
\label{subsec:deelvraag3a}

Om er voor te zorgen dat statistieken in Adcurve te verklaren zijn wordt de volgende vraag gesteld:
\textit{Wat zijn de gerelateerde technische factoren waardoor de scenario's voor verhindering zorgen in de huidige situatie?} \\

Ieder scenario wordt hier besproken met de technische reden verklaard.

\begin{enumerate}
    \item In de huidige situatie wordt alle data in een proces verwerkt. Voor alle webwinkels en publishers. 
    
    \item Daarnaast wordt er iedere dag een deel van de week, maand en jaar aggregatie berekend. Om gegevens uit vorige maand te corrigeren moeten er op verschillende aggregatie niveau 's \textit{MapReduce jobs} worden uitgevoerd.
    Dit soort problemen kunnen worden voorkomen door alleen berekeningen uit te voeren op het aller laagste niveau, en de aggregaties aan de client side 
        
    \item Omdat alle data in een keer wordt geaggregeerd kan het proces pas worden gestart nadat alle afhankelijke data bronnen beschikbaar zijn. Door een publisher wordt de data beschikbaar gemaakt na 10 uur s\'ochtends
\end{enumerate}

\subsubsection{\textbf{Conclusie}}

Een deel van het probleem is het actief monitoren van de data kwaliteit en processen starten om het te corrigeren. Hier wordt niet verder op in gegaan omdat een dergelijke oplossing hiervoor buiten scope valt.

Deze problemen spelen op doordat er niet de mogelijkheid is om de data aggregatie opnieuw te genereren binnen voorspelbare tijd. De grootste technische beperking is dat een dag aan data, een dag duurt om te aggregeren.

Eerder zijn de functionele eisen al besproken in hoofdstuk \ref{sec:deelvraag1} te lezen in tabel \ref{table:requirements}. Om te voorkomen dat een nieuwe techniek mogelijk dezelfde probleem situaties introduceert, worden de volgende non functionele eisen toegevoegd.
\begin{itemize}
    \item voor probleem scenario 2 moet data in groepen van webwinkels worden uitgevoerd om er voor te zorgen dat: webwinkels uit verschillende tijdzones op tijd klaar zijn. Dit zijn non functionele eisen. 
    
    \item Data aggregaties moeten plaatsvinden zodra kosten beschikbaar zijn per publisher
    
    \item voor probleem scenario 1 en 4, moet mogelijk zijn om voor een individuele webwinkels de data te aggregeren zodat er correcties kunnen worden gemaakt bij data kwaliteit issues. 
    \item de snelheid waarmee data wordt verwerkt moet snel genoeg zijn om 30 dagen aan data binnen 1 dag te verwerken.
    
    \item De tijd die het kost voor data aggregaties moet voorspelbaar zijn, dit kan worden berijkt  wanneer de oplossing lineair schaalbaar is.
\end{itemize}

Deze criteria moeten worden toegepast bij het verder selecteren van mogelijke oplossingen. 


\clearpage

% ACTIVITY Oplossing ontwerpen voor use-cases en Proof of concept

\subsection{Vergelijkingstabel technieken en strategieën}
\label{subsec:deelvraag3b}

\textit{Wat zijn de mogelijke strategieën en technieken om dit op te lossen?} \\


Het process moet kan worden aangeroepen met drie  parameters: Shop id, publisher id en datum \\

\textbf{Data preperation}
De eerste fase uit het algoritme is een ETL stap, om csv en bson te converteren naar een uniform schema.
De geconverteerde data wordt weg geschreven in bestanden per webwinkel als een methode om eenmalig te filteren i.p.v. meerdere malen tijdens het aggregatie proces. \\




    

\textbf{Stategie 1, Hardware application} 
Het is praktisch mogelijk om data in sub sets te aggregeren omdat er een afzonderlijke data bron is per publisher. 
Het gebruiken van gesplitste bestanden per webshop zorgt voor kleine  en korte processen. Dit kan met verschillende technologieën worden geimplementeerd, voornamlijk General purpose languages, DSL, Hardware oplossingen. \\

De totale performance hoeft niet te verbeteren, zolang het proces dat alleen data aggregatie uitvoert voor de specifieke webwinkel en publisher kort van duur is kan dit worden uitgevoerd op verschillende machines tegelijk om dit schaalbaar in te zetten. \\
    
\textbf{Strategie 2, Networked application}
Alle data in een groep aggregeren, (op timezone en op publisher niveau). snel genoeg zodat er iedere dag de afgelopen 30 dagen wordt verwerkt.
Dit kan met verschillende databases, Hadoop en Spark \\

\textbf{Strategie 3, Hybriede oplossing} Calculus..
door eenmalig de data aggregatie uit te voeren in een suboptimaal systeem kunnen alle huidige problemen alsnog worden opgelost door delta's te berekenen tussen de huidige state en de gecorrigeerde data. Vervolgens worden alle delta's in bestanden weg geschreven. \\

Er is een origineel bestand voor de data aggregaties. Meerdere mogelijke bestanden met delta's en een proces dat de delta's toepast en een uiteindelijk gecorrigeerde versie van aggregaties genereerd en opslaat. 
Zo zullen er meerdere versies van een aggregatie in s3 beschikbaar zijn. Onze web api moet de logica toepassen om altijd de laatste versie uit te serveren. 
(om aan de eisen te voldoen en data beschikbaar te maken voor kantoor uren moet de data worden geagregeerd in verschillende delen, per publishser wanneer de data beschikbaar is. Dit kan een aanpassing zijn in de huidige oplossing, of worden gedaan met een ander systeem)


\clearpage


% ACTIVITY Bespreken van ontwerpen en evt. aanpassen van ontwerpen
% ACTIVITY Vastleggen kwaliteitscriteria Proof of concept's
\section{Ontworpen experimenten middels proof of concept}
\label{sec:deelvraag4}

Wat zijn de mogelijke oplossingen en hoe wordt dit gevalideerd?

Alle mogelijke oplossingen zijn besproken met het team, hierin is besloten dat er 3 mogelijke POC's worden uitgevoerd met de volgende technologieën:

\begin{itemize}
    \item Golang
    \item Apache Spark
\end{itemize}

\textbf{Databases} worden niet overwogen vanwege het programmeermodel, deze is zeer productief maar is niet eenvoudig te testen. Daarnaast heeft de organisatie niet de expertise om een Shared nothing database systeem (een cluster van machines) in een productie omgeving te onderhouden en te schalen. \\

\textbf{Parallel programming} wordt gebruikt in het POC met Spark. Door gebruik te maken van distributed functionaliteiten van Spark wordt getest of de snelheid waar spark bekend om staat (paper) behaald kan worden in onze use case. Er is de mogelijkheid om unit tests en functional tests te schrijven, dit wordt aangeboden door het framework.
het wegschrijven van meerdere resultaten in een proces kan door het partitionener van output data op (PublisherID, ShopID). Ook kunnen er meerdere dagen in een proces worden verwerkt en het resultaat wordt weggeschreven per TimeID, PublisherID en ShopID
\\

Als \textbf{Hardware oplossing} wordt gebruik gemaakt van Golang. Hierbij zal de performance van multicore processors worden getest. Deze taal is vergelijkbaar met C++ in zijn performance. Uit test resultaten door \cite{lee2010debunking} is gevonden dat een MapReduce operaties (Monte Carlo algoritme) sneller is op een CPU in vergelijking met een GPU (Te programmeren via eerder besproken andere DSL) "We typically find that the highest performance is achieved when multiple threads are used per core. For Core i7, the best performance comes from running 8 threads on 4 cores" \parencite{lee2010debunking} \\

\textbf{De volgende kwaliteits eisen zijn vastgelegd aan ieder POC} \\

TODO

% De aanroep van het process moet data uit de volgende datasets uit s3 lezen:
% de visits (csv) dump uit Cassandra, orders (bson) dump uit MongoDb, Geïmporteerde advertentiekosten van diverse publishers (csv)

\clearpage

% ACTIVITY Uitvoeren van Proof of concept's
% Eerste iteratie
% Tweede iteratie
% Derde iteratie
\section{deelvraag 5 - Conclusies}
\label{sec:deelvraag5}
%  Wat zijn de gepresenteerde oplossingen en waarom zijn deze volledig of niet?

\textbf{Go Aggregator}
Split all orders and visits for all shops (264 shops)

\begin{lstlisting}
2016/05/11 11:38:45 Begin
2016/05/11 11:40:09 Main Done
./start.sh  69.83s user 16.12s system 101% cpu 1:24.70 total

total time: 1 minute 9 seconds
\end{lstlisting}

\textbf{Spark all shop products, file per shop}

(one file contains all products for all channels)

\begin{lstlisting}
16/05/11 10:09:58 INFO SparkContext: Running Spark version 1.6.0
[2016-05-11 10:10:03] Start loading data
[2016-05-11 10:12:24] Finished writing data
Total time:     0:02:21.378717
16/05/11 10:12:24 INFO ShutdownHookManager: Deleting directory /private/var/folders/tp/….

time without job submit: 2 minutes 21 seconds
\end{lstlisting}


\textbf{Conclusie}

[todo]

Het gebruik van big data systemen is zeer schaalbaar, maar introduceerd een hoop overhead. (paper). 

Voordelen van een programmeer taal is dat complexe business logic hierin kan worden geschreven zonder rekening te houden met veel abstracties zoals in parallel programming zoals map reduce of sql.. In zo'n paradigm moet een probleem naar code worden vertaalt met extra kennis naast het programmeren, kennis over het map reduce paradigm, sql join. Daarnaast wordt code vertaalt naar een query plan en het gebruik van indexes etc..

