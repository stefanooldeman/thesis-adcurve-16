\textit{Wat zijn de probleem scenario's waardoor gegevens niet te verklaren zijn, en wat zijn de mogelijke oplossingen?}

Tijdens de project analyse is met verschillende stakeholders binnen de organisatie gesproken. Naast de gedefinieerde projecteisen zijn er verschillende symptomen verzameld. Deze zijn gebruikt voor het samenstellen van een Impact analyse gemaakt, zie Apendix \ref{app:impact_analyse}

Vervolgens is per probleemscenario een mogelijke technische verklaring gezocht, zijn er criteria omschreven waaraan de gebruikte technologie bij een mogelijk oplossing moet voldoen. Hierdoor wordt getoetst of de geselecteerde technologieën in \ref{sec:gevonden_tools} toepasbaar zijn en de huidige probleem scenario werkelijk kunnen oplossen.

\subsection{Scenario's uit de Impact Analyse}

\begin{enumerate}
    \item L6: API 's provided by the publisher are unavailable
    \item M5: API 's for google, change frequently and the import stops working, or fail silent (values are not matched,,resulting in empty fields)
    \item H6: Wrong costs by configuration, issues: mistakes in tracking Order amount, tracked wrong, multiplied by 100 bug
    \item L7: Metrics calculated incorrectly because of mismatching product data (ids from tracking don't match cost exports from publisher)
    \item L7: Calculations fail,because technology or infrastructure 
    \item L4: Aggregations from different dimensions on the same data
    don't match
    \item H7 Bij het bekijken van dashboards in Adcurve zijn de gegevens over de vorige dag pas beschikbaar na 12:30 CET. Omdat alle data in een keer wordt verwerkt wordt het proces gestart nadat alle afhankelijke data bronnen beschikbaar zijn.
\end{enumerate}

Scenario een (1) tot en met vier (4) zijn niet te voorkomen omdat de organisatie zelf hier weinig invloed op kan hebben. Het wordt veroorzaakt door externe processen bij publishers, of mensen in diesnt van de webwinkel die de advertenties of webwinkel integraties verkeerd configureren. Scenario vijf (5) en zes (6) hebben een hoge impact en zijn specifieke problemen met de huidige implementatie. Deze scenario's zijn te voorkomen door het inzetten van andere technologie of een andere strategie als het aan komt op data processing.
Scenario 7 is eerder besproken tijdens de non functionele eisen in \ref{table:requirements}. Deze is opgenomen zodat onderzocht wordt hoe dit het best kan worden voorkomen.  

\clearpage

\subsection{Technische te verklaren oorzaken}

Met betrekking tot scenario vijf (5) en zeven (6) zijn verschillende problemen gevonden in relatie tot de gebruikte versie van MongoDB \parencite{mongo_changelog}. Uit monitoring systemen zijn de foutmeldingen terug te relateren aan software bugs die aanwezige zijn in versie 2.4.

De consensus binnen de organisatie is dat een upgrade naar een volgende versie riskant is. Het is niet in te schatten hoe veel problemen er zullen optreden. Daarnaast moeten er processen worden ingericht om het synchroniseren van order te ondersteunen en data verlies te voorkomen wanneer de database offline moet.
% TODO: is het mogelijke om machines van verschillende versies naast elkaar te draaien in een cluster?
    
Met betrekking tot scenario zeven (7) zijn de volgende mogelijke oorzaken gevonden:

\begin{itemize}
    \item Uit monitoring systemen blijkt dat het online productie processen van invloed zijn op de performance van het aggregatie proces. Omdat MongoDB direct wordt gebruikt voor het synchroniseren van bestellingen met webwinkels, en dit een realtime proces is, wordt het cluster hiermee belast. In de huidige situatie worden de MapReduce jobs op een aantal machines in het cluster uitgevoerd, toch word de performance beïnvloed.
    \item het aggregeren van data kan in MongoDB wellicht trager zijn dan nodig omdat de tussentijdse resultaten uit de fases in MapReduce worden weggeschreven naar verschillende machines \parencite{mongo_mr_shards}. Zo valt ook af te lezen uit monitoring dat het wegschrijven van de uiteindelijk resultaten langer duurt dan het aggregeren zelf. Dit heeft mogelijk te maken met het bijhouden van indexes.  \parencite{mongo_write_performance}
    % replica sets? sharding? grootte cluster?
\end{itemize}


\subsubsection{\textbf{Conclusie}}
\label{subsec:3.3.2}

Tijdens de root cause analysis zijn een aantal oorzaken omschreven. Hieruit valt te concluderen dat een mogelijke nieuwe oplossing aan de volgende criteria moet voldoen:

\begin{enumerate}[label=(\alph*)]

    % Er rekening moet worden gehouden met de mogelijke overhead van networking applications, en tegelijkertijd de mogelijkheid moet zijn om grootte data sets op te splitsen zodat er geen ``disk spills"\ optreden.
    \item In de nieuwe situatie moet op efficiënte wijze worden om gegaan met een kleine hoeveelheid aan data, zodat de verschillende fases van het aggregeren (zoals map, reduce, shuffle en sort). Dit omdat voor 80\% van de webshops een kleine hoeveelheid data wordt verzameld. Tegelijkertijd is de input data set groot en zijn resultaten van aggregaties wellicht groter. Er moet in deze situatie op efficiënte wijze data worden weg geschreven naar een eindlocatie,  zoals het filesysteem. Hierbij moet het onderhouden van indexes worden voorkomen.
    
    \item Er moet situaties situatie worden voorkomen waarin het onmogelijk is om een technologie of systeem te upgraden naar een nieuwere versie. Dit is te voorkomen door a) geen state te bewaren in het systeem zelf, maar dit alleen te gebruiken bij data processing. b) door het systeem onafhankelijk te maken van productie / online processen. Dit biedt de mogelijkheid door bijvoorbeeld een database back-up te doen, het systeem te migreren en de data opnieuw in te laden.
\end{enumerate}

\clearpage


\subsection{Hoe wordt dit voorkomen met de gevonden tools / POC?}
\label{subsec:deelvraag3_vergelijking}


\subsubsection{\textbf{Versie upgrades}}

Door de tools binnen het Hadoop ecosysteem wordt geen state bewaard. Maar alle data wordt beheerd door HDFS en opgeslagen als toegankelijke bestanden in een gekozen bestandsformaat. Het risico is dat het upgraden van versies, niet compatible met verschillende bestands formaten. Ook de tools die opereren op het data formaat moeten compatible zij. Daarnaast bestaat de mogelijkheid dat HDFS data anders beheerd onder verschillende versies. Hierdoor zijn data migraties erg operationeel intensief is. Hierdoor is het sterk aan te raden om dit niet zelf te beheren, maar gebruik te maken van distributie zoals Amazon EMR, Hortonworks, Cloudera of MapR.

Omdat Spark onder andere uitmaakt van het Hadoop ecosysteem zijn deze conclusies te generaliseren.

Omdat databases bij definitie statefull zijn, moet er in dit geval een back-up en restore mogelijkheid aanwezig zijn om upgrades te kunnen uitvoeren.

In het geval van Golang, dat in het algemeen niet als data processing tool te beschouwen is maar als een General purpose language, is de implementatie code eenvoudig te upgraden naar nieuwere versies. Dit wordt gegarandeerd als de implementatie volledig getest is door unit tests. 


\subsubsection{\textbf{Mogelijke overhead voorkomen}}

\begin{verbatim}

Use the COST PAPER (single threading vs. network overhead)

https://www.usenix.org/conference/hotos15/workshop-program/presentation/mcsherry

AND The paper measuring NETWORK OPTIMIZATIONS vs CPU/MEM in DATA PROCESSING TOOLS VS CPU
https://www.usenix.org/system/files/conference/nsdi15/nsdi15-paper-ousterhout.pdf

Reference to the paper and explain:
SPARK USES NO INDEX \parencite{armbrust2015spark}
MAP REDUCE (Google / Apache) USES NO INDEX 
SHARED NOTHING DATABASES USE NO INDEXES \parencite{lamb2012vertica} of \parencite{harizopoulos2008oltp} / \parencite{dewitt2006build}

MAYBE ALSO APPLY 'Amdahls law'
https://en.wikipedia.org/wiki/Amdahl%27s_law

 AND MAYBE 
"roughly 80\% of the effects come from 20\%"
https://en.wikipedia.org/wiki/Pareto_principle

\end{verbatim}


\subsubsection{\textbf{Oplosing om  high query speed en good analytics performance te behalen met  twee losse systemen}}

Het splitsen van data verwerken en data opslag / opvragen betekend dat de geaggregeerde data zal worden opgeslagen in s3, zodat de bestaande API de data kan uitserveren. 
De aggregaties op basis van week, jaar en maand komen te vervallen. De overige aggregatie die nodig is om API client snel te houden wordt gedaan door Saki. Doordat de bestanden gesorteerd worden opgeslagen op s3, kan saki deze binnen 100 milliseconden aggregeren per query.

Dit heeft als gevolg dat data opslag volledig verplaatst naar Amazon S3, zowel de input data als de output data. (data pipeline)

    
\subsection{Conclusie}

Een deel van het probleem is het actief monitoren van de data kwaliteit en processen starten om het te corrigeren. Hier wordt niet verder op in gegaan omdat een dergelijke oplossing hiervoor buiten scope valt. Hiervoor geldt, zodra er een oplossing is moeten de datakwaliteit worden herstelt door het proces te starten dat de correcties uitvoert [``effected datasources"\ opnieuw evalueren]
Deze scenario's zijn ook tegelijkertijd lastig te voorkomen, alleen te herstellen. Het advies is daarom om hier ``monitoring en alerting\ voor te implementeren en verder onderzoek doen naar bestaande methodieken voor beheersen van datakwaliteit. Bijvoorbeeld door starten van een ``Data Stewardship Program" zoals omschreven wordt in het ``TDWI Report, The Data Warehouse Institute"\ door  \textcite{eckerson2002data}.

Spark SQL is bewezen snel erg snel te zijn en Amazon EMR is managed service

database column store heeft geen indexes maar partities, bewezen erg snel te zijn… maar geen voordelen worden behaald omdat  ons proces altijd N-max aantal columns worden opgevraagd. Daarom zal de query nooit sneller zijn, unless er meerdere query 's zijn waarbij verschillende columnen worden opgevraagd. Daarom zijn er te weinig voordelen om hier een POC mee te starten, daarnaast zullen versie upgrades lastig zijn. 

De Aggregatie processen met Golang zullen erg klein worden gemaakt door de data van te voren te partitioneren per shop. Dit biedt de mogelijkheid om het deze processen uit te voeren op verschillende machines (scale-out), door het gebruikt van resqueue workers "Resque workers can be distributed between multiple machines, support priorities, are resilient to memory bloat / "leaks," \parencite{github2016reque} 


Kort: Er wordt niet verder geïnvesteerd in een POC met databases omdat er te veel keuze is, en technologie niet effectief is toe te passen

Wel wordt er een POC uitgevoerd met Golang en Spark


% Het splitsen van data verwerken en een databases waaruit de data is op te vragen, heeft met gevolg dat Saki, een applicatie die in real time aggregaties op het hoogste niveau pakt (channel, shop, shop_product_id) en deze flexibel aggregeerd op basis van datum.