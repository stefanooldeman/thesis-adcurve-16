\textit{Wat zijn de probleem scenario's waardoor gegevens niet te verklaren zijn, en wat zijn de mogelijke oplossingen?}

% Hiervoor zijn anekdotes verzameld van stakeholders waarbij zei vertelden over scenario 's die voor verwarring zorgen bij gebruikers.
Uit interview met verschillende stakeholders binnen shop2market zijn een aantal problematische scenario's besproken. Deze hebben geleidt tot de functionele en non functionele eisen in tabel \ref{table:requirements}. Tijdens de interviews zijn veel symptomen besproken en de impact op de organisatie en de klanten van Shop2market. Hier worden deze scenario's en hun impact inzichtelijk gemaakt.

% "the right tool for the job"
In het de vorige deelvraag in \ref{sec:deelvraag2} is een shortlist gepresenteerd van geschikte technologieën voor een POC's.
Niet alleen moet een oplossing overeenkomen met de requirements, maar een verkeerde inzet van een technologie moet door deze analyse te voorkomen zijn.

De vraag wordt in delen beantwoord: Wat zijn de probleem scenario's, wat is hiervan de achterliggende oorzaak, en hoe kan dit worden opgelost?


% Wat zijn de probleem scenario's
\subsection{Impact analyse}

In tabel / bijlage (impact analyse) zijn de volgende scenario's geclassificeerd in verschillende categorieën. Hieruit valt af te lezen wat de werkelijke impact is, en welke prioriteit (severity) het probleem daarom krijgt.


Scenario 1 en 2 [Costs Missing] zijn niet te voorkomen, (advies: implementeer detectie). Scenario 3 en 4 [Costs Incorrect] zijn lastig te detecteren, komt niet vaak voor

Voor de hierboven besproken scenario's geldt: zodra er een oplossing is moeten de datakwaliteit worden herstelt door het proces te starten dat de correcties uitvoert ["effected datasources" opnieuw evalueren]
Deze scenario's zijn ook tegelijkertijd lastig te voorkomen, alleen te herstellen. Het advies is daarom om hier "monitoring en alerting" voor te implementeren. Zie ook andere maatregelen zoals bijv. het aanwijzen van Data stewards (TODO: reference term, paper)

Scenario 5 komt soms voor en heeft een grootte impact doordat het herstel momenteel erg veel tijd kost.


Scenario 6 is specifiek probleem met de huidige implementatie en komt soms voor. 
TODO: vraag Stanislav voor technische redenen, kennis etc.
  

% \item Bij het bekijken van dashboards in Adcurve zijn de gegevens over de vorige dag pas beschikbaar na 12:30 CET. Omdat alle data in een keer wordt geaggregeerd kan het proces worden gestart nadat alle afhankelijke data bronnen beschikbaar zijn. Door een publisher wordt de data beschikbaar gemaakt na 10 uur s\'ochtends. Daarom start het proces pas om 11 uur. \\ H6
% Api not available,for admarkt, kieskeurig etc & L6
% Apis' for google,change and the import stops working, or fail silent (values are not matched,,resulting in empty fields) & M5
% Configuration or bugs & Wrong costs by configuration, issues: mistakes in tracking Order amount, tracked wrong, multiplied by 100 bug & H6
% Costs incorrect & Metrics calculated incorrectly & L7
% Stats not available & Calculations fail,because technology or infrastructure & L7
% Aggregations \newline don't match & Aggregations from different dimensions on the same data don't match & L4


\subsection{Technische te verklaren oorzaken}

Zoals besproken zijn scenario 5 en 6 mogelijk te voorkomen. Dit in conjunction met de non functional requirements besproken in \ref{sec:deelvraag1} zijn de voornaamste redenen om naar een andere oplossing te zoeken.

De volgende technische redenen huidige implementatie zijn bekend binnen de organisatie

% MongoDB version 2.4
% https://docs.mongodb.com/v2.4/core/map-reduce/

\begin{itemize}
    \item inladen en wegschrijven van resultaten duurt lang => versnel IO operaties. "After every insert, update, or delete operation, MongoDB must update every index associated with the collection in addition to the data itself. Therefore, every index on a collection adds some amount of overhead for the performance of write operations."
    % https://docs.mongodb.com/v2.4/core/write-performance/
    
    \item "Your working set should stay in memory to achieve good performance. Otherwise many random disk IO’s will occur, and unless you are using SSD, this can be quite slow." 
    % https://docs.mongodb.com/v2.4/faq/diagnostics/
    
    \item Niet voldoende hardeschijfruimte
    "MongoDB supports multiple record allocation strategies that determine how mongod adds padding to a document when creating a record. Because documents in MongoDB may grow after insertion and all records are contiguous on disk, the padding can reduce the need to relocate documents on disk following updates. Relocations are less efficient than in-place updates and can lead to storage fragmentation. As a result, all padding strategies trade additional space for increased efficiency and decreased fragmentation." % https://docs.mongodb.com/manual/core/mmapv1/#record-allocation-strategies
    
    "The usePowerOf2Sizes flag changes the method that MongoDB uses to allocate space on disk for documents in this collection. By setting usePowerOf2Sizes, you ensure that MongoDB will allocate space for documents in sizes that are powers of 2 (e.g. 4, 8, 16, 32, 64, 128, 256, 512...8388608). With usePowerOf2Sizes, MongoDB will be able to more effectively reuse space."
    % https://docs.mongodb.com/v2.4/reference/command/collMod/#usePowerOf2Sizes
    
    \item map reduce algoritme in een notedop:
    "mongos retrieves the results from each shard, performs a merge sort to order the results, and proceeds to the reduce/finalize phase as needed. mongos then writes the result to the output collection in sharded mode."
    % https://docs.mongodb.com/v2.4/core/map-reduce-sharded-collections/
    
    \item 1 systeem voor analytics workload (mapreduce) en de reporting interface => mapreduce in 1 systeem en resultaten op 2e systeeem bijv. S3
    
    \item random mapreduce failures => geen onderhoud van cluster
    \item - opruimen resterende data bij failures => geen entropy
    \item productie load (transacties) heeft invloed op performance => onafhankelijk systeem van productie
\end{itemize}



\subsection{Hoe wordt dit voorkomen met de gevonden tools / POC?}
hoe wordt dit voorkomen met de gevonden tools / POC?


- conclusie
    - data pipeline design
        - oplossing om  high query speed en good analytics performance te behalen met  twee losse systemen
        - S3 als datawarehouse storage ipv een database (geen limitations)
    - query speed wordt opgelost door extern systeem (Saki)
    - nieuwe systeeem voor mapreduce hebben de bestaande problemen niet omdat:
        - netwerken voorkomen wordt, workers zijn bewezen duizenden jobs aan te kunnen (kleine processen)
        - spark in memory oplossing is bewezen snel te zijn en EMR is managed service
        - (database column store heeft geen indexes maar partities, bewezen erg snel te zijn… maar geen voordelen worden behaald omdat  ons proces altijd N-max aantal columns wordt gebruikt opgevraagd)



\subsection{Conclusie}

% Een deel van het probleem is het actief monitoren van de data kwaliteit en processen starten om het te corrigeren. Hier wordt niet verder op in gegaan omdat een dergelijke oplossing hiervoor buiten scope valt.