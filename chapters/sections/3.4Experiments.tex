% \textbf{Hardware oplossing met Golang}
% Het is praktisch mogelijk om data in sub sets te aggregeren omdat er een afzonderlijke data bron is per publisher.
% Het gebruiken van gesplitste bestanden per webshop zorgt voor zeer korte levende processen. De totale performance hoeft niet te verbeteren, zolang het proces dat alleen data aggregatie uitvoert voor de specifieke webwinkel en publisher kort van duur is kan dit worden uitgevoerd op verschillende machines tegelijk om dit schaalbaar in te zetten. "We typically find that the highest performance is achieved when multiple threads are used per core. For Core i7, the best performance comes from running 8 threads on 4 cores" \parencite{lee2010debunking}

% \textbf{Distributed oplossing met Spark}
% Door gebruik te maken van distributed functionaliteiten van Spark wordt getest of de snelheid waar spark bekend om staat (paper) behaald kan worden in onze use case. Er is de mogelijkheid om unit tests en functional tests te schrijven, dit wordt aangeboden door het framework. Het wegschrijven van meerdere resultaten in een proces kan door het partitionener van output data op (PublisherID, ShopID). Ook kunnen er meerdere dagen in een proces worden verwerkt en het resultaat wordt weggeschreven per TimeID, PublisherID en ShopID


In dit hoofdstuk worden gepresenteerd hoe de POC / expirimenten zijn ontworpen. Zoals is te lezen in \ref{sec:deelvraag3} is zijn de best mogelijke oplossingen te ontwikkelen met behulp van \textit{Golang} en \textit{Apache Spark}. In overeenstemming met de organisatie zijn verdere succesfactoren gedefinieerd per POC.


% De uitvoer van het project bestaat uit drie fases; Data preperation, Go Aggregate en Spark SQL
% In fase 1 vindt de ETl processing plaats. Als de resultaten snel genoeg zijn, zal dit worden hergebruikt in fase 2 en 3.
% TODO Leg uit dat Spark SQL niet wordt aangeraden voor ETL wanneer dit alleen mapping fases heeft


\subsection{Ontworpen expirimenten}

zoals wordt omschreven in de originele doelstelling in \ref{sec:doelstelling} ``moet data op tijd worden verwerkt evenals het tijdig herstellen van fouten mogelijk zijn".  Daarom valideert dit expiriment welke oplossinge de beste prestatie levert in de huidige situatie (context).

Voor het meten van performance worden er drie vershillende type aggregaties uitgevoerd op "commodity hardware", de exacte specificaties worden later omschreven in sectie \ref{subsec:3.4hardware_specs}.  Er wordt gebruik gemaakt van een productie data set van één willekeurige dag.

Tijdens iedere aggregatie worden er twee metingen: de totale proces \footnote{tijd word gemeten door unix `time` zie de documentatie voor time: \url{http://linux.die.net/man/1/time}} en de totale tijd zonder de warmup time.  Warmup time wordt in dit expiremnt omschreven als de tijd die nodig tussen het starten van het proces en het werkelijk uitvoeren van de geschreven implementatie. Dit zal worden toegelicht per POC.

Voor het evalueren van de twee POCs is besloten om geen latency, IO, memory of CPU gerelateerde benchmarks te evalueren.
% Veelal omdat dit inzicht geeft in de prestaties van de hardware. En omdat door de  academia en industry veel energie investeerd in het verbeteren van performance van bijv. data processing tools zoals hadoop en spark.
Voor de doelstellingen van het project is de totale proces tijd belangrijker.


\subsection{Gebruikte data sets}

Tijdens de drie fases van het expirement wordt inconsistent gebruik gemaakt van een data set uit productie als data input. De data set bestaat uit visits en orders van 264 webwinkels uit de benelux.

\begin{itemize}
    \item Het \textbf{Orders} bestand is origineel 0.2494 GB groot, dit is in een Binary JSON (BSON) compressie formaat, Na het ETL waarbij alleen de alleen de relevantie metrieken overblijven is de dataset 0.04734 GB groot. Dit is een JSON formaat waarbij alle extra colommen voor visits ook zijn inbegrepen en een default waarde hebben.

    \item Het \textbf{Visits} bestand is orgineel 1.0GB groot, dit is in een CSV bestand waarbij de TAB charachter als delimiter wordt gebruikt.  Na het ETL waarbij alleen de alleen de relevantie metrieken overblijven is de dataset 0.04734 GB groot. Dit is hetzelfde JSON formaat waarbij alle extra colommen voor orders zijn ingebrepen en een default waarde hebben.
\end{itemize}

Het resultaat van de ETL voor orders en visits wordt als input data gebruikt voor iedere aggregatie. De drie aggregaties zijn variaties waarbij dezelfde input data wordt gebruikt, maar waarvan het resultaat verschilt per aggregatie in data grootte. Dit is om de huidige situatie en business needs te simuleren. Een grotere data set past wellicht wel of niet in het geheugen (RAM). De drie variates maken gebruik van de volgende keys waarop de aggregatie functie \verb=SUM(metric)= wordt toegepast:

\begin{itemize}
    \item TimeId, ChannelID
    \item TimeId, ChannelID, ShopId
    \item TimeId, ChannelID, ShopId, ShopProductId
\end{itemize}

Ieder opdracht (aggregatie) wordt in één serie vijf keer herhaalt, waarvan een vervolgens de twee metingen worden geregistreerd. Over de metingen wordt een gemiddelde genomen.

\subsection{ETL Process, Data preperation}

De eerste fase uit het algoritme is een ETL stap, om csv en bson te converteren naar een uniform schema.
dit heeft de volgende voordelen
% de visits (csv) dump uit Cassandra, orders (bson) dump uit MongoDb, Geïmporteerde advertentiekosten van diverse publishers (csv)


download data sets, unzip, run splitter. bson naar json en csv naar json.
de structuur van orders bson is als volgt

de structuur van visits bson is als volgt

dit resulteert in het volgende schema
data wordt weg geschreven in bestanden per webwinkel
dit heeft de volgende reden / voordelen
% als een methode om eenmalig te filteren i.p.v. meerdere malen tijdens het aggregatie proces.


\subsection{Golang}

- wat zijn de eisen die zijn besproken

- de oplossing is als volgt ontworpen

- de gevonden resultaten

- warmup time is in gecompileerde Go code niet van toepassing.
Omdat Golang compileerd naar assembly is er geen sprake van warmup time

\subsection{Spark}

- wat zijn de eisen die zijn besproken

- de oplossing is als volgt ontworpen

- de gevonden resultaten

- warmup time
De warmup tijd in spark is te verklaren doordat de Spark SQL syntax wordt veraalt naar Java, het de java code wordt vertaal naar systeem code door de JVM.


\subsection{De setup}
\label{subsec:3.4hardware_specs}







