\textit{Wat zijn de probleem scenario's waardoor gegevens niet te verklaren zijn, en wat zijn de mogelijke oplossingen?}

Tijdens de project analyse is met verschillende stakeholders binnen de organisatie gesproken. Naast de gedefinieerde projecteisen zijn er verschillende symptomen verzameld. Deze zijn gebruikt voor het samenstellen van een Impact analyse, zie appendix \ref{app:impact_analyse}

Vervolgens is er een root-cause analysis uitgevoerd. Voor ieder probleem scenario wordt een mogelijke technische verklaring gezocht. Op basis van dit inzicht zijn er criteria omschreven waaraan een mogelijk oplossing moet voldoen. Hierdoor wordt getoetst of de geselecteerde technologieën in \ref{sec:gevonden_tools} toepasbaar zijn, en de huidige probleem scenario 's werkelijk worden opgelost.

\subsection{Scenario's uit de Impact Analyse}

\begin{enumerate}
    \item L6: API's provided by the publisher are unavailable
    \item M5: API's for google, change frequently and the import stops working, or fail silent (values are not matched, resulting in empty fields)
    \item H6: Wrong costs by configuration, issues: mistakes in tracking Order amount, tracked wrong, multiplied by 100 bug
    \item L7: Metrics calculated incorrectly because of mismatching product data (ids from tracking don't match cost exports from publisher)
    \item L7: Calculations fail,because technology or infrastructure 
    \item L4: Aggregations from different dimensions on the same data
    don't match
    \item H7 Bij het bekijken van dashboards in Adcurve zijn de gegevens over de vorige dag pas beschikbaar na 12:30 CET. Omdat alle data in een keer wordt verwerkt wordt het proces gestart nadat alle afhankelijke data bronnen beschikbaar zijn.
\end{enumerate}

Scenario een (1) tot en met vier (4) zijn niet te voorkomen omdat de organisatie zelf hier weinig invloed op kan hebben. Het wordt veroorzaakt door externe processen bij publishers, of mensen in dienst van de webwinkel die de advertenties of webwinkel integraties verkeerd configureren. Scenario vijf (5) en zes (6) hebben een hoge impact en zijn specifieke problemen met de huidige implementatie. Deze scenario's zijn te voorkomen door het inzetten van andere technologie of een andere strategie als het aan komt op data processing.
Scenario 7 is eerder besproken tijdens de non functionele eisen in \ref{table:requirements}. Deze is opgenomen zodat onderzocht wordt hoe dit het best kan worden voorkomen.  

\clearpage

\subsection{Technische te verklaren oorzaken}

Met betrekking tot scenario vijf (5) en zes (6) zijn verschillende problemen gevonden in relatie tot de gebruikte versie van MongoDB \parencite{mongo_changelog}. Uit monitoring systemen zijn de foutmeldingen terug te relateren aan software bugs die aanwezige zijn in versie 2.4.

De consensus binnen de organisatie is dat een upgrade naar een volgende versie riskant is. Het is niet in te schatten hoe veel problemen er zullen optreden. Daarnaast moeten er processen worden ingericht om het synchroniseren van bestellingen te ondersteunen en data verlies te voorkomen wanneer de database offline moet.
% TODO: is het mogelijke om machines van verschillende versies naast elkaar te draaien in een cluster?
    
Met betrekking tot scenario zeven (7) zijn de volgende mogelijke oorzaken gevonden:

\begin{itemize}
    \item Uit monitoring systemen blijkt dat het online productie processen van invloed zijn op de performance van het aggregatie proces. Omdat MongoDB direct wordt gebruikt voor het synchroniseren van bestellingen met webwinkels, en dit een realtime proces is, wordt het cluster hiermee belast. In de huidige situatie worden de MapReduce jobs op een aantal machines in het cluster uitgevoerd, toch word de performance beïnvloed.
    \item het aggregeren van data kan in MongoDB wellicht trager zijn dan nodig omdat de tussentijdse resultaten uit de fases in MapReduce worden weggeschreven naar verschillende machines \parencite{mongo_mr_shards}. Zo valt ook af te lezen uit monitoring dat het wegschrijven van de resultaten langer duurt dan het aggregeren zelf. Dit heeft mogelijk te maken met het bijhouden van indexes.  \parencite{mongo_write_performance}
\end{itemize}


\subsubsection{\textbf{Conclusie}}
\label{subsec:3.3.2}

Tijdens de root cause analysis zijn een aantal oorzaken omschreven. Hieruit valt te concluderen dat een mogelijke nieuwe oplossing aan de volgende criteria moet voldoen:

\begin{enumerate}[label=(\alph*)]
    % Er rekening moet worden gehouden met de mogelijke overhead van networking applications, en tegelijkertijd de mogelijkheid moet zijn om grootte data sets op te splitsen zodat er geen ``disk spills"\ optreden.
    \item In de nieuwe situatie moet op efficiënte wijze worden om gegaan met een kleine hoeveelheid aan data. Dit omdat voor 80\% van de webshops een kleine hoeveelheid data wordt verzameld (zie ter illustratie appendix \ref{app:partities}). Tegelijkertijd is de input dataset groot en zijn resultaten van aggregaties wellicht groter. Er moet in deze situatie op efficiënte wijze data worden weg geschreven naar een eindlocatie,  zoals het filesysteem. Hierbij moet het onderhouden van indexes worden voorkomen.
    
    \item In de nieuwe situatie moet worden voorkomen dat een technologie of systeem niet te upgraden is naar een nieuwere versie. Dit is te voorkomen door geen state te bewaren in het systeem zelf, maar dit alleen te gebruiken voor data processing.
    
    \item In de nieuwe situatie wordt er gekozen om het data aggregatie systeem onafhankelijk te maken van productie processen. Dit moet voorkomen dat productie processen van invloed zijn op de performance van het aggregatie proces. Dit is mogelijk door te werken met exports van databases die worden opgeslagen in Amazon S3
\end{enumerate}

\clearpage


\subsection{Zijn de gevonden technologieën gevalideerd?}
\label{subsec:deelvraag3_vergelijking}

\subsubsection{\textbf{Versie upgrades}}

Door gebruikt te maken van Amazon EMR (Elastic Map Reduce) hoeft er geen cluster te worden geïnstalleerd. Met parameters wordt aangegeven wat de grootte van het cluster moet zijn, en welke code er wordt uitgevoerd. EMR beheerd de verschillende versies van Spark en gerelateerde componenten.

Golang is een General purpose language, met de aanwezigheid van unittests is de implementatie volledig getest tegen de versie van de programmertaal. Bij een upgrade zullen er verandereing nodig zijn aan de implementatie, maar er is geen sprake van een stateful systeem.

\subsubsection{\textbf{Mogelijke overhead voorkomen}}

In het geval van Spark wordt er geen gebruik gemaakt van indexes. \parencite{armbrust2015spark}. Echter moet er worden getest tijdens het POC of er sprake is van mogelijke overhead.

In een naïeve implementatie met Golang zal er geen gebruik gemaakt van optimalisatie technieken, daarom is er ook geen sprake van overhead.

% Use the COST PAPER (single threading vs. network overhead)
% https://www.usenix.org/conference/hotos15/workshop-program/presentation/mcsherry

% AND The paper measuring NETWORK OPTIMIZATIONS vs CPU/MEM in DATA PROCESSING TOOLS VS CPU
% https://www.usenix.org/system/files/conference/nsdi15/nsdi15-paper-ousterhout.pdf

    
\subsection{Conclusie}

Een deel van de probleem scenario's kan alleen worden opgelost wanneer deze tijdig worden gedetecteerd. Het advies is daarom om hier ``monitoring en alerting\ voor te implementeren en verder onderzoek te doen naar bestaande methodieken voor het beheersen van datakwaliteit. Bijvoorbeeld door het starten van een ``Data Stewardship Program"\ zoals omschreven wordt in ``TDWI Report, The Data Warehouse Institute"\ door \textcite{eckerson2002data}. Dit wordt niet verder onderzocht omdat dit buiten scope valt.

In \ref{subsec:deelvraag3_vergelijking} is omschreven hoe de gevonden technologieën omgaan met de probleem scenario's, en technische oorzaken. 
Omdat de problemen te voorkomen zijn in de gevonden technologieën zijn Spark en Golang gevalideerd en kunnen de POC worden geimplementeerd.

In sectie \ref{subsec:3.3.2} werd geconcludeerd dat de nieuwe situatie op efficiënte wijze moet omgegaan met een kleine hoeveelheid aan data. Dit criteria is niet concreet te beantwoorden en zal worden gevalideerd per POC.