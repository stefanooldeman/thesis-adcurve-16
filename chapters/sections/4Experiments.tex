Wat zijn de mogelijke oplossingen en hoe wordt dit gevalideerd?

In dit hoofdstuk wordt omschreven hoe de Proof of Concept 's op basis van Golang en Spark zijn uitgevoerd. Zoals is te lezen in \ref{sec:gevonden_tools} is er voor gekozen om de POC te ontwikkelen met van Golang en Apache Spark. Hieruit moet blijken of de technologieën die geselecteerd zijn in het onderzoek ook werkelijk toepasbaar zijn in de context.

Zoals wordt omschreven in de originele doelstelling in \ref{sec:doelstelling}
``moet data op tijd worden verwerkt evenals het tijdig herstellen van fouten mogelijk zijn". Daarom valideert dit experiment welke oplossing de beste prestatie levert in de huidige situatie.

Het expiriment bestaat uit twee fases. Eerst wordt er een Map fase uitgevoerd en vervolgens een Reduce, zoals bij MapReduce. De map fase is 
ETL en de reduce fase is een aggregatie met Golang of Spark SQL.

\subsection{Gebruikte methode}

Voor ieder POC worden er twee metingen uitgevoerd: de totale proces tijd, gemeten door GNU time \parencite{gnu_time}. En de totale tijd zonder de tijd tussen het starten van het proces en het werkelijk uitvoeren van de implementatie (ook wel warmup-time genoemgd). Dit wordt in één serie vijf keer herhaalt, waarvan een vervolgens de twee metingen worden geregistreerd. Over de metingen wordt een gemiddelde genomen en dit wordt vormt het resultaat.

Tijdens de drie fases van het experiment wordt gebruik gemaakt van een dataset uit productie als data input. De data set bestaat uit visits en orders van 264 webwinkels.

\begin{table}[h]
\centering
\caption{Gebruikte data bronnen met eigenschappen}
\label{tab:datasets}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
data bron & datagrootte voor & datagrootte na & aantal regels voor & aantal regels na \\ \hline
orders.bson    &  0.2494 GB & 0.04734 GB       & N/A                & 31.869           \\ \hline
visits.json & 1.064 GB               & 0.3986 GB      & 2.345.341          & 2.345.090        \\ \hline
\end{tabular}
\end{table}


\subsection{ETL}

ETL (Extract, Transform and Load) is een manier om data uit een externe databron te transformeren naar een ander schema \parencite{data-mining}. Dit zorgt voor een uniform formaat waardoor latere processen geen logica hoeven toe te passen om met de data te werken. In tabel \ref{tab:etl_input_example} is het dataformaat omschreven van de visits data bron. Iedere regel in dit bestand representeert een bezoek op de website van een webshop. Na het uitvoeren van het ETL proces worden er twee bestanden weg geschreven, een per webshop het bestand ``./exports/910/visits.json"\ bevat een regel en het bestand ``./exports/224/visits.json" heeft twee regels. Een voorbeeld hiervan is te vinden in appendix \ref{app:json_format}

Tijden de ETL wordt er kolom toegevoegd: \verb+Traffic=1+, dit is een vorm van data interpretatie. Dit komt ook ten goede van de data consistentie omdat de data interpretatie van data in één fase plaatsvindt. De vervolg fases kunnen hierdoor gebruik maken van pure functies die in een framework, technologie of taal zijn geïmplementeerd.

\begin{table}[bh]
\centering
\caption{Een voorbeeld van de input data gebruikt tijdens ETL}
\label{tab:etl_input_example}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
timestamp  & time\_id & publisher\_id & shop\_id & shop\_product\_id & shop\_category\_id \\ \hline
1464154281 & 20160424 & 410         & 224      & 103774145         & 338790             \\ \hline
1464154306 & 20160424 & 61          & 910      & 108837485         & 6782117            \\ \hline
1464154314 & 20160424 & 410         & 224      & 100670758         & 9152995            \\ \hline
\end{tabular}
\end{table}


Het ETL proces is in de eerste iteratie van het project  geschreven in Golang. Hier is voor gekozen omdat er meer betere ondersteuning is voor data formaten zoals BSON, een binary formaat. Als laatste is er voor gekozen om data op te splitsen per webshop als een methode van data partitionering. Dit biedt de mogelijkheid om in latere fases gebruik te maken van concurrency of parallellisatie implementaties, omdat data kan worden verwerkt in een proces per partitie. 
Uit onderzoek blijkt dat MapReduce deze methode gebruikt om data te schalen naar een terabyte schaal.

In de ETL fase is dat verwerkt voor 265 webshops. Er worden daarom met twee databronnen maximaal 530  (= 265 * 2) bestanden geschreven. Maar omdat het kan dat sommige webwinkels geen data heeft voor een databron wordt er geen bestand weg geschreven. Met de huidige dataset resulteerde het ETL proces in 462 bestanden.

En hierop volgende fase representeert de reduce fase van een MapReduce algoritme. De input voor dit het reduce proces is het resultaat van de ETL fase.

\clearpage

% data verlies van -0.010702068483857997 voor visits

\subsection{Golang}

Om het proces te starten wordt de locatie van een de data partities van shop. Ter voorbeeld: \newline\verb+./bin/go_aggregator ./exports/1001/+
De implementatie gebruikt voor iedere databron een aparte thread (goroutine) om de data in te lezen. Een apart thread wordt gebruikt om de data te ontvangen en voert de aggregatie functie SUM uit op alle kolommen. Alle data wordt gegroepeerd op basis van de key ShopID, PublisherID, en ProductID. Er zijn geen bijzonderheden gevonden waaruit blijkt dat dit proces niet schaalbaar is in te zetten.

Het verwerken van een partitie gebeurt tussen de 1.4 seconden en de 2 milliseconden. En als het het programma wordt uitgevoerd voor alle webwinkels duurt dit 1 minuut en 22 seconden.

\subsection{Spark}

Voor spark is de opdracht gegeven aan het cluster dat in standalone modus is gestart. Er is 7 GB geheugen beschikbaar gesteld en 8 CPU cores. Om het proces te starten voor spark wordt eer een bestand gegeven gegeven aan het spark-submit commando. Ter voorbeeld:\newline\verb+spark-submit query.py --input ./exports_combined.json+

De implementatie gebruikt Spark SQL in een python script "query.py". Tijdens het proof of concept is gevonden dat de beste performance wordt behaald wanneer alle data in een groot bestand wordt gegeven. Spark voert hier zelf de optimale partitionering in over de beschikbare hardware. Daarom worden eerst alle bestanden samengevoegd met het volgende unix commando:\newline\verb+cat ./exports/*/{orders,visits}.json >> exports_combined.json+.


In Spark is er wel spraken van warmup-time, dit is te verklaren doordat de Spark SQL syntax wordt vertaalt naar Java, de java code wordt vertaal naar systeem code door de JVM.

Het verwerken van alle partities gebeurt in 3 minuten en 22 seconden, en de tijd zonder warmup-time is 2 minutes 21 seconds.



\subsection{Gebruikte Hardware}
\label{subsec:hardware_specs}

Tijdens het onderzoek naar verschillende technologiën zijn ook benchmarks gevonden. Hierbij wordt er vaak gepretendeert dat er een schaalbaarheid kan worden bereikt door het gebruiken van "Commodity hardware". Hiermee worden machines bedoelt die algemeen beschikbaar zijn, geen bijzondere performance voordelen bieden. Om in deze trend te blijven is er voor gekozen om geen speciale omgeving te installeren voor de experimenten. Uiteindelijk is er gebruik gemaakt van een Macbook Pro met de volgende specificaties:

\begin{table}[h]
\caption{Hardware specificaties van de gebruikte machine}
\label{tab:hardware_specs}
\begin{tabular}{ll}
Merk:      & MacBook Pro (Retina, 13-inch, Mid 2014) \\
Processor: & 2.6 GHz Intel Core i5                   \\
Geheugen:  & 8 GB 1600 MHz DDR3                      \\
Storage:   & Apple SSD                                  
\end{tabular}
\end{table}

\subsection{Overige vragen}

Voor het evalueren van de twee POC 's is besloten om geen latency, IO, memory of CPU gerelateerde benchmarks te evalueren. Dit is wel gewoonlijk bij industrie benchmarks van verschillende data processing tools. Maar dit wordt gedaan vanuit een competitief perspectief  \parencite{ousterhout2015making}. Voor de doelstellingen van dit project is de totale proces tijd belangrijker.
